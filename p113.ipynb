{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mssnowy/p113/blob/main/p113.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVe_ge-0KTVn"
      },
      "source": [
        "## Load Data\n",
        "\n",
        "**Image Dataset Directory Structur**e:\n",
        "\n",
        "**Note: The directory and sub-directory names shown here are only for explanation purposes which might differ from the code.**\n",
        "\n",
        "Suppose if we have a master directory(folder) of the Images then we can subdivide it into “Training”, “Validation” & “Testing” images sub-directories(sub-folder). \n",
        "\n",
        "And then the “Training” directories contain sub-directories(sub-folders) called “Infected” and “Uninfected” which contain appropriate images in the respective sub-directories.\n",
        "\n",
        "Similarly, the “Validation'' & “Testing” directory also contains sub-directories(sub-folders) called “Infected” and “Uninfected” which contain appropriate images in the respective sub-directories.\n",
        "\n",
        "\n",
        "**Training**: Images in this directory will be used for the training of the data.\n",
        "\n",
        "**Validation**: Images in this directory will be used to validate the model training. The validation dataset allows us to see how well the data generalises the classification.\n",
        "\n",
        "**Testing**: Images in this directory will be used to test how well the model is trained.\n",
        "<img src=\"https://s3-whjr-curriculum-uploads.whjr.online/2467514a-e93f-4a0f-8e20-b3893dfa9144.jpeg\" width= 600>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xCYT8gXKTVq",
        "outputId": "154098d4-8df9-4c82-f171-c4c095cf6232"
      },
      "source": [
        "!git clone https://github.com/procodingclass/PRO-M3-Hurricane-Damage-Dataset"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PRO-M3-Hurricane-Damage-Dataset'...\n",
            "remote: Enumerating objects: 800, done.\u001b[K\n",
            "remote: Total 800 (delta 0), reused 0 (delta 0), pack-reused 800\u001b[K\n",
            "Receiving objects: 100% (800/800), 2.07 MiB | 4.21 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsYLdBlzh8pl"
      },
      "source": [
        "## Visualise the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgYg_hzRh7fn"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "from matplotlib.image import imread\n",
        "\n",
        "training_infected_image = \"/content/PRO-M3-Hurricane-Damage-Dataset/train/damage/image (1).jpeg\"\n",
        "\n",
        "# load image pixels\n",
        "image = imread(training_infected_image)\n",
        "\n",
        "pyplot.title(\"Damage: Image 1\")\n",
        "\n",
        "# plot raw pixel data\n",
        "pyplot.imshow(image)\n",
        "\n",
        "# show the figure\n",
        "pyplot.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0nG4OkcN26G"
      },
      "source": [
        "## Image Preprocessing\n",
        "\n",
        "1. Convert each image to an array\n",
        "2. Map each image labels\n",
        "3. Augment the each image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtXxDq1O4okc"
      },
      "source": [
        "### Image Preprocessing: Mapping each image with labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DIAsjUd343_"
      },
      "source": [
        "<center><b>Mapping Each Image With Labels</b><br><img src=\"https://s3-whjr-curriculum-uploads.whjr.online/1bdade80-2a32-4fc2-8902-f18067803dba.jpeg\" width= 1000>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6cHrlB-5xQ4"
      },
      "source": [
        "### Image Preprocessing: Data Augmentation\n",
        "\n",
        "A few Data Augemtation Techniques:\n",
        "\n",
        "*   Image Rotation\n",
        "*   Image Height & Width Shift\n",
        "*   Image Horizontal & Vertical Flipping\n",
        "*   Image Resizing\n",
        "*   Image Zooming\n",
        "\n",
        "\n",
        "<img src=\"https://s3-whjr-curriculum-uploads.whjr.online/5403e9b1-a339-405d-98b3-36826ec3f04a.gif\" width= 400>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaY4vj6-qr00"
      },
      "source": [
        "## Image Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4y81Wp6766s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a45c479-a636-44d9-8c27-2f0b097c5618"
      },
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "training_data_generator = ImageDataGenerator(rotation_range=90,fill_mode='nearest')\n",
        "training_image_directory = '/content/PRO-M3-Hurricane-Damage-Dataset'\n",
        "training_augmented_images = training_data_generator.flow_from_directory(training_image_directory,target_size=(180,180))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 799 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot\n",
        "from matplotlib.image import imread\n",
        "for i in range(4):\n",
        "  pyplot.subplot(2,2,i+1)\n",
        "  batch = training_augmented_images.next()\n",
        "  image = batch[0][0].astype('uint8')\n",
        "  pyplot.imshow(image)\n",
        "\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "4FSs12E17Fsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_augmented_images.class_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoVQJIn98aNk",
        "outputId": "316e64cf-56fe-44a3-8cc7-5ca24a6e77a3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.git': 0, 'test': 1, 'train': 2, 'validate': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64,(3,3),activation = 'relu',input_shape=(180,180,3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64,(3,3),activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(128,(3,3),activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(128,(3,3),activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "    tf.keras.layers.Dense(512,activation='relu'),\n",
        "    tf.keras.layers.Dense(2,activation='softmax'),\n",
        "])"
      ],
      "metadata": {
        "id": "1RN-9GlCLAYS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "bZg23S8zLYGV",
        "outputId": "9235cf53-1869-4487-c2cd-f770c58cea8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 178, 178, 64)      1792      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 89, 89, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 87, 87, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 43, 43, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 41, 41, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 20, 20, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 18, 18, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 9, 9, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 10368)             0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 10368)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               5308928   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,570,114\n",
            "Trainable params: 5,570,114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from re import VERBOSE\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "history=model.fit(training_augmented_images,epochs=2,verbose=True)\n",
        "model.save('hurricane.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6NEdRCGTObbm",
        "outputId": "e8554f6b-029a-4587-dbfe-8eb067bd19e3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-f8197bcdedff>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mre\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVERBOSE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_augmented_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hurricane.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/binary_crossentropy/logistic_loss/mul/BroadcastGradientArgs' defined at (most recent call last):\n    File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.9/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/ioloop.py\", line 687, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/ioloop.py\", line 740, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 821, in inner\n      self.ctx_run(self.run)\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 782, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-13-f8197bcdedff>\", line 3, in <cell line: 3>\n      history=model.fit(training_augmented_images,epochs=2,verbose=True)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1054, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer.py\", line 542, in minimize\n      grads_and_vars = self.compute_gradients(loss, var_list, tape)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer.py\", line 275, in compute_gradients\n      grads = tape.gradient(loss, var_list)\nNode: 'gradient_tape/binary_crossentropy/logistic_loss/mul/BroadcastGradientArgs'\nIncompatible shapes: [32,2] vs. [32,4]\n\t [[{{node gradient_tape/binary_crossentropy/logistic_loss/mul/BroadcastGradientArgs}}]] [Op:__inference_train_function_6773]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.image import imread\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "testing_image_directory='/content/PRO-M3-Hurricane-Damage-Dataset/testing_dataset/infected'\n",
        "img_files=os.listdir(testing_image_directory)\n",
        "i=0\n",
        "for file in img_files[51:60]:\n",
        "  img_files_path=os.path.join(testing_image_directory,file)\n",
        "  img_1=load_img(img_files_path,target_size=(180,180))\n",
        "  img_2=img_to_array(img_1)\n",
        "  img_3=np.expand_dims(img_2,axis=0)\n",
        "  prediction= model.predict(img_3)\n",
        "  predict_class= np.argmax(prediction,axis=1)\n",
        "  pyplot.subplot(3,3,i+1)\n",
        "  pyplot.imshow(img_2.astype('uint8'))\n",
        "  pyplot.title(predict_class[0])\n",
        "  pyplot.axis('on')\n",
        "  i=i+1\n",
        "\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "jo4lJQhPQCOu",
        "outputId": "0b884d7a-2310-4042-e2ed-aeb7d30d8949"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-401d1e137dcc>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtesting_image_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/PRO-M3-Hurricane-Damage-Dataset/testing_dataset/infected'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mimg_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_image_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m51\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/PRO-M3-Hurricane-Damage-Dataset/testing_dataset/infected'"
          ]
        }
      ]
    }
  ]
}